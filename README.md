# Intro: 
__*Ever wanted to control a robot via hand gestures?*__ You’ve come to the right place! This project is an implementation of a hand gesture controlled robot. This project was completed by Nathan Faber and Sander Miller, for the course [Computational Robotics](https://comprobo20.github.io/) @[Olin College of Engineering](https://www.olin.edu/).

This project was chosen to further explore algorithms in computer vision. This project was scoped to allow us to learn about multiple parts of computer vision processing. Our plan was to utilize a deep-learning object detection model to localize the hand and then use color thresholding and a variety of image processing techniques to determine how many fingers are showing. This data is then used to change/control the neato’s movement.

# Goal of project
This project seeks to show a working implementation of the above methods/techniques such that others could understand our process and that we could understand more about how these types of problems are tackled in industry.
